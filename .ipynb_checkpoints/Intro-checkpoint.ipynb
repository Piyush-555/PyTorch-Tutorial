{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n",
      "GPU Available? True\n",
      "CUDA Toolkit version: 9.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"GPU Available? {}\".format(torch.cuda.is_available()))\n",
    "print(\"CUDA Toolkit version: {}\".format(torch.version.cuda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[7, 6, 5, 3],\n",
      "        [1, 3, 2, 4],\n",
      "        [7, 5, 7, 4],\n",
      "        [8, 3, 4, 3],\n",
      "        [7, 1, 2, 3]], dtype=torch.int32)\n",
      "tensor([1, 2, 3], device='cuda:0')\n",
      "tensor([[7, 6, 5, 3],\n",
      "        [1, 3, 2, 4],\n",
      "        [7, 5, 7, 4],\n",
      "        [8, 3, 4, 3],\n",
      "        [7, 1, 2, 3]], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Creating nd-array\n",
    "x_cpu = torch.tensor([1,2,3]) #int (Factory function, better than torch.Tensor)\n",
    "z = np.random.randint(1, 9, (5,4))\n",
    "y_cpu = torch.tensor(z)\n",
    "print(x_cpu)\n",
    "print(y_cpu)\n",
    "\n",
    "# Transfer of tensor to GPU\n",
    "x_gpu = x_cpu.cuda()\n",
    "y_gpu = y_cpu.cuda()\n",
    "print(x_gpu)\n",
    "print(y_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([5, 4])\n",
      "tensor([[7, 6, 5, 3, 1, 3, 2, 4, 7, 5, 7, 4, 8, 3, 4, 3, 7, 1, 2, 3]],\n",
      "       device='cuda:0', dtype=torch.int32) torch.Size([1, 20])\n",
      "tensor([[7, 6, 5, 3, 1],\n",
      "        [3, 2, 4, 7, 5],\n",
      "        [7, 4, 8, 3, 4],\n",
      "        [3, 7, 1, 2, 3]], device='cuda:0', dtype=torch.int32) torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Shape and Reshape\n",
    "x = x_gpu\n",
    "y = y_gpu\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "y = y.reshape(1,20)\n",
    "print(y, y.shape)\n",
    "\n",
    "y = y.reshape(4,5)\n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor constructor\n",
    "torch.Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tensor() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7e00321110a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: tensor() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "torch.tensor(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.4721e+21, 2.8799e+32, 4.5713e+07, 3.9760e+12],\n",
       "        [7.5338e+28, 1.5975e-43, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([1,2,3,4]) #float (Constructor)\n",
    "t = t.cuda()\n",
    "print(t.dtype)\n",
    "print(t.device)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.9816, 0.1399],\n",
      "        [0.5713, 0.5401],\n",
      "        [0.7138, 0.3257]])\n",
      "tensor([[2., 4.],\n",
      "        [1., 2.],\n",
      "        [0., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.eye(3))\n",
    "print(torch.zeros(3,2))\n",
    "print(torch.ones(3,2))\n",
    "print(torch.rand(3,2))\n",
    "print(torch.randint(low=0, high=9, size=(3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.]) tensor([1, 2, 3], dtype=torch.int32) tensor([1, 2, 3], dtype=torch.int32) tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1., 2., 3.]) tensor([1, 2, 3], dtype=torch.int32) tensor([0, 0, 0], dtype=torch.int32) tensor([0, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Which tensor?\n",
    "x = np.array([1,2,3])\n",
    "t1 = torch.Tensor(x) #copy\n",
    "t2 = torch.tensor(x) #--||-- best\n",
    "t3 = torch.as_tensor(x) #share memory ... faster better for performance\n",
    "t4 = torch.from_numpy(x) #--||--\n",
    "\n",
    "print(t1, t2, t3, t4)\n",
    "x[0] = 0\n",
    "x[1] = 0\n",
    "x[2] = 0\n",
    "print(t1, t2, t3, t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "2\n",
      "12 tensor(12)\n"
     ]
    }
   ],
   "source": [
    "# shape, size, num_dim, num_elements\n",
    "t = torch.tensor(torch.randint(0,9,(3,4)))\n",
    "print(t.shape)\n",
    "print(t.size())\n",
    "print(len(t.shape))\n",
    "print(t.numel(), torch.tensor(t.shape).prod())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [4.],\n",
      "        [8.],\n",
      "        [7.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [4.]])\n",
      "tensor([[1., 0., 1., 6., 5., 4., 8., 7., 2., 1., 0., 4.]])\n",
      "tensor([[1., 0., 1.],\n",
      "        [6., 5., 4.],\n",
      "        [8., 7., 2.],\n",
      "        [1., 0., 4.]])\n",
      "tensor([[[1., 0., 1.],\n",
      "         [6., 5., 4.]],\n",
      "\n",
      "        [[8., 7., 2.],\n",
      "         [1., 0., 4.]]])\n",
      "tensor([1., 0., 1., 6., 5., 4., 8., 7., 2., 1., 0., 4.])\n",
      "tensor([1., 0., 1., 6., 5., 4., 8., 7., 2., 1., 0., 4.])\n",
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [6.],\n",
      "        [5.],\n",
      "        [4.],\n",
      "        [8.],\n",
      "        [7.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [4.]])\n",
      "tensor([[1., 0., 1., 6., 5., 4., 8., 7., 2., 1., 0., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# reshape, squeeze, unsqueeze \n",
    "print(t.reshape(12,1))\n",
    "print(t.reshape(1,12))\n",
    "print(t.reshape(4,3))\n",
    "print(t.reshape(2,2,3))\n",
    "\n",
    "print(t.reshape(12)) #similar to\n",
    "print(t.reshape(12,1).squeeze()) #this #removes axis having length==1\n",
    "print(t.reshape(12,1).squeeze().unsqueeze(dim=1)) #adds axis of length==1\n",
    "print(t.reshape(12,1).squeeze().unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]]) torch.Size([4, 2])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Concatenation (all dims must be same except dim)\n",
    "t1 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "\n",
    "t2 = torch.tensor([\n",
    "    [5,6],\n",
    "    [7,8],\n",
    "])\n",
    "\n",
    "print(torch.cat((t1, t2), dim=0), torch.cat((t1, t2), dim=0).shape) #along rows \n",
    "print(torch.cat((t1, t2), dim=1), torch.cat((t1, t2), dim=1).shape) #along columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7333, 0.5122, 0.7753, 0.0173],\n",
       "         [0.9667, 0.5604, 0.1653, 0.8452],\n",
       "         [0.1223, 0.0436, 0.3820, 0.8861],\n",
       "         [0.3424, 0.1746, 0.4871, 0.3199]],\n",
       "\n",
       "        [[0.6535, 0.2321, 0.0108, 0.5431],\n",
       "         [0.2511, 0.0877, 0.5980, 0.4096],\n",
       "         [0.9545, 0.9060, 0.3269, 0.1480],\n",
       "         [0.8392, 0.3641, 0.4413, 0.6219]],\n",
       "\n",
       "        [[0.8892, 0.9692, 0.7900, 0.5730],\n",
       "         [0.5718, 0.1975, 0.9567, 0.1934],\n",
       "         [0.7268, 0.6221, 0.0131, 0.9334],\n",
       "         [0.7215, 0.9250, 0.9192, 0.5642]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Say we've 3 images of 4x4\n",
    "img = torch.rand(3,4,4)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8456, 0.8930, 0.8963, 0.1004],\n",
       "          [0.6906, 0.9467, 0.6855, 0.1087],\n",
       "          [0.6575, 0.3361, 0.7960, 0.9133],\n",
       "          [0.6898, 0.3938, 0.6714, 0.3909]]],\n",
       "\n",
       "\n",
       "        [[[0.7562, 0.2515, 0.7144, 0.7035],\n",
       "          [0.9623, 0.0396, 0.7433, 0.2672],\n",
       "          [0.3591, 0.4417, 0.8384, 0.9660],\n",
       "          [0.1684, 0.2653, 0.7823, 0.5586]]],\n",
       "\n",
       "\n",
       "        [[[0.2405, 0.5505, 0.0433, 0.2975],\n",
       "          [0.4254, 0.4756, 0.0422, 0.7856],\n",
       "          [0.2945, 0.2153, 0.8032, 0.1956],\n",
       "          [0.2446, 0.0705, 0.3230, 0.7800]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to add channel dimension (channel first)\n",
    "img = img.reshape(3,1,4,4)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.56934115]\n",
      "   [0.95820521]\n",
      "   [0.25099581]\n",
      "   [0.14312819]]\n",
      "\n",
      "  [[0.33849178]\n",
      "   [0.12566881]\n",
      "   [0.87987867]\n",
      "   [0.0682118 ]]\n",
      "\n",
      "  [[0.65580585]\n",
      "   [0.14582132]\n",
      "   [0.52972853]\n",
      "   [0.82393492]]\n",
      "\n",
      "  [[0.0494063 ]\n",
      "   [0.57666539]\n",
      "   [0.98290107]\n",
      "   [0.79161715]]]\n",
      "\n",
      "\n",
      " [[[0.00879947]\n",
      "   [0.36219316]\n",
      "   [0.41666167]\n",
      "   [0.11140953]]\n",
      "\n",
      "  [[0.49922693]\n",
      "   [0.53387784]\n",
      "   [0.26413302]\n",
      "   [0.73376895]]\n",
      "\n",
      "  [[0.70252488]\n",
      "   [0.65052317]\n",
      "   [0.3604827 ]\n",
      "   [0.79248669]]\n",
      "\n",
      "  [[0.27495483]\n",
      "   [0.43089277]\n",
      "   [0.72297158]\n",
      "   [0.30674049]]]\n",
      "\n",
      "\n",
      " [[[0.19248517]\n",
      "   [0.31134571]\n",
      "   [0.35531728]\n",
      "   [0.9558256 ]]\n",
      "\n",
      "  [[0.73706336]\n",
      "   [0.85456986]\n",
      "   [0.28617647]\n",
      "   [0.88695422]]\n",
      "\n",
      "  [[0.23979107]\n",
      "   [0.6462338 ]\n",
      "   [0.09299462]\n",
      "   [0.13532622]]\n",
      "\n",
      "  [[0.5808097 ]\n",
      "   [0.68338738]\n",
      "   [0.06095831]\n",
      "   [0.13478282]]]]\n",
      "[[[[0.56934115 0.95820521 0.25099581 0.14312819]\n",
      "   [0.33849178 0.12566881 0.87987867 0.0682118 ]\n",
      "   [0.65580585 0.14582132 0.52972853 0.82393492]\n",
      "   [0.0494063  0.57666539 0.98290107 0.79161715]]]\n",
      "\n",
      "\n",
      " [[[0.00879947 0.36219316 0.41666167 0.11140953]\n",
      "   [0.49922693 0.53387784 0.26413302 0.73376895]\n",
      "   [0.70252488 0.65052317 0.3604827  0.79248669]\n",
      "   [0.27495483 0.43089277 0.72297158 0.30674049]]]\n",
      "\n",
      "\n",
      " [[[0.19248517 0.31134571 0.35531728 0.9558256 ]\n",
      "   [0.73706336 0.85456986 0.28617647 0.88695422]\n",
      "   [0.23979107 0.6462338  0.09299462 0.13532622]\n",
      "   [0.5808097  0.68338738 0.06095831 0.13478282]]]] (3, 1, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "# PyTorch uses channels first, whereas TensorFlow user channels last\n",
    "# Convert channels last image to channels first\n",
    "img = np.random.rand(3,4,4,1)\n",
    "print(img)\n",
    "img = np.moveaxis(img, -1, 1)\n",
    "print(img, img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5693, 0.9582, 0.2510, 0.1431],\n",
      "         [0.3385, 0.1257, 0.8799, 0.0682],\n",
      "         [0.6558, 0.1458, 0.5297, 0.8239],\n",
      "         [0.0494, 0.5767, 0.9829, 0.7916]]], dtype=torch.float64)\n",
      "tensor([[0.5693, 0.9582, 0.2510, 0.1431],\n",
      "        [0.3385, 0.1257, 0.8799, 0.0682],\n",
      "        [0.6558, 0.1458, 0.5297, 0.8239],\n",
      "        [0.0494, 0.5767, 0.9829, 0.7916]], dtype=torch.float64)\n",
      "tensor([0.5693, 0.9582, 0.2510, 0.1431], dtype=torch.float64)\n",
      "tensor(0.5693, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Breakdown of batch of images\n",
    "img = torch.tensor(img)\n",
    "print(img[0]) #0th image\n",
    "print(img[0][0]) #1st colour channel of oth image\n",
    "print(img[0][0][0])#1st row of 0th image\n",
    "print(img[0][0][0][0])#1st element of 0th image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5693, 0.9582, 0.2510, 0.1431, 0.3385, 0.1257, 0.8799, 0.0682, 0.6558,\n",
      "        0.1458, 0.5297, 0.8239, 0.0494, 0.5767, 0.9829, 0.7916, 0.0088, 0.3622,\n",
      "        0.4167, 0.1114, 0.4992, 0.5339, 0.2641, 0.7338, 0.7025, 0.6505, 0.3605,\n",
      "        0.7925, 0.2750, 0.4309, 0.7230, 0.3067, 0.1925, 0.3113, 0.3553, 0.9558,\n",
      "        0.7371, 0.8546, 0.2862, 0.8870, 0.2398, 0.6462, 0.0930, 0.1353, 0.5808,\n",
      "        0.6834, 0.0610, 0.1348], dtype=torch.float64)\n",
      "tensor([[0.5693, 0.9582, 0.2510, 0.1431, 0.3385, 0.1257, 0.8799, 0.0682, 0.6558,\n",
      "         0.1458, 0.5297, 0.8239, 0.0494, 0.5767, 0.9829, 0.7916],\n",
      "        [0.0088, 0.3622, 0.4167, 0.1114, 0.4992, 0.5339, 0.2641, 0.7338, 0.7025,\n",
      "         0.6505, 0.3605, 0.7925, 0.2750, 0.4309, 0.7230, 0.3067],\n",
      "        [0.1925, 0.3113, 0.3553, 0.9558, 0.7371, 0.8546, 0.2862, 0.8870, 0.2398,\n",
      "         0.6462, 0.0930, 0.1353, 0.5808, 0.6834, 0.0610, 0.1348]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.5693, 0.9582, 0.2510, 0.1431, 0.3385, 0.1257, 0.8799, 0.0682, 0.6558,\n",
      "         0.1458, 0.5297, 0.8239, 0.0494, 0.5767, 0.9829, 0.7916],\n",
      "        [0.0088, 0.3622, 0.4167, 0.1114, 0.4992, 0.5339, 0.2641, 0.7338, 0.7025,\n",
      "         0.6505, 0.3605, 0.7925, 0.2750, 0.4309, 0.7230, 0.3067],\n",
      "        [0.1925, 0.3113, 0.3553, 0.9558, 0.7371, 0.8546, 0.2862, 0.8870, 0.2398,\n",
      "         0.6462, 0.0930, 0.1353, 0.5808, 0.6834, 0.0610, 0.1348]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Flatten\n",
    "# Say we want flattened images\n",
    "print(img.flatten()) #everything flattened\n",
    "print(img.flatten(start_dim=1)) #each image flattened\n",
    "# OR\n",
    "print(img.reshape(img.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
