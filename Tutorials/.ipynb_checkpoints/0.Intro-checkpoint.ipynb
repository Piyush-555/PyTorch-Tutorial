{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n",
      "GPU Available? True\n",
      "CUDA Toolkit version: 9.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"GPU Available? {}\".format(torch.cuda.is_available()))\n",
    "print(\"CUDA Toolkit version: {}\".format(torch.version.cuda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[2, 6, 5, 4],\n",
      "        [2, 6, 2, 4],\n",
      "        [2, 4, 6, 7],\n",
      "        [6, 4, 8, 6],\n",
      "        [6, 7, 7, 1]], dtype=torch.int32)\n",
      "tensor([1, 2, 3], device='cuda:0')\n",
      "tensor([[2, 6, 5, 4],\n",
      "        [2, 6, 2, 4],\n",
      "        [2, 4, 6, 7],\n",
      "        [6, 4, 8, 6],\n",
      "        [6, 7, 7, 1]], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Creating nd-array\n",
    "x_cpu = torch.tensor([1,2,3]) #int (Factory function, better than torch.Tensor)\n",
    "z = np.random.randint(1, 9, (5,4))\n",
    "y_cpu = torch.tensor(z)\n",
    "print(x_cpu)\n",
    "print(y_cpu)\n",
    "\n",
    "# Transfer of tensor to GPU\n",
    "x_gpu = x_cpu.cuda()\n",
    "y_gpu = y_cpu.cuda()\n",
    "print(x_gpu)\n",
    "print(y_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([5, 4])\n",
      "tensor([[2, 6, 5, 4, 2, 6, 2, 4, 2, 4, 6, 7, 6, 4, 8, 6, 6, 7, 7, 1]],\n",
      "       device='cuda:0', dtype=torch.int32) torch.Size([1, 20])\n",
      "tensor([[2, 6, 5, 4, 2],\n",
      "        [6, 2, 4, 2, 4],\n",
      "        [6, 7, 6, 4, 8],\n",
      "        [6, 6, 7, 7, 1]], device='cuda:0', dtype=torch.int32) torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Shape and Reshape\n",
    "x = x_gpu\n",
    "y = y_gpu\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "y = y.reshape(1,20)\n",
    "print(y, y.shape)\n",
    "\n",
    "y = y.reshape(4,5)\n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor constructor\n",
    "torch.Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tensor() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7e00321110a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: tensor() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "torch.tensor(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor([1,2,3,4]) #float (Constructor)\n",
    "t = t.cuda()\n",
    "print(t.dtype)\n",
    "print(t.device)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.eye(3))\n",
    "print(torch.zeros(3,2))\n",
    "print(torch.ones(3,2))\n",
    "print(torch.rand(3,2))\n",
    "print(torch.randint(low=0, high=9, size=(3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1,2,3], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which tensor?\n",
    "x = np.array([1,2,3])\n",
    "t1 = torch.Tensor(x) #copy\n",
    "t2 = torch.tensor(x) #--||-- best\n",
    "t3 = torch.as_tensor(x) #share memory ... faster better for performance\n",
    "t4 = torch.from_numpy(x) #--||--\n",
    "\n",
    "print(t1, t2, t3, t4)\n",
    "x[0] = 0\n",
    "x[1] = 0\n",
    "x[2] = 0\n",
    "print(t1, t2, t3, t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape, size, num_dim, num_elements\n",
    "t = torch.tensor(torch.randint(0,9,(3,4)))\n",
    "print(t.shape)\n",
    "print(t.size())\n",
    "print(len(t.shape))\n",
    "print(t.numel(), torch.tensor(t.shape).prod())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape, squeeze, unsqueeze \n",
    "print(t.reshape(12,1))\n",
    "print(t.reshape(1,12))\n",
    "print(t.reshape(4,3))\n",
    "print(t.reshape(2,2,3))\n",
    "\n",
    "print(t.reshape(12)) #similar to\n",
    "print(t.reshape(12,1).squeeze()) #this #removes axis having length==1\n",
    "print(t.reshape(12,1).squeeze().unsqueeze(dim=1)) #adds axis of length==1\n",
    "print(t.reshape(12,1).squeeze().unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]]) torch.Size([4, 2])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Concatenation (all dimensions must be same except dim)\n",
    "t1 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "\n",
    "t2 = torch.tensor([\n",
    "    [5,6],\n",
    "    [7,8],\n",
    "])\n",
    "\n",
    "print(torch.cat((t1, t2), dim=0), torch.cat((t1, t2), dim=0).shape) #along rows \n",
    "print(torch.cat((t1, t2), dim=1), torch.cat((t1, t2), dim=1).shape) #along columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Say we've 3 images of 4x4\n",
    "img = torch.rand(3,4,4)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to add channel dimension (channel first)\n",
    "img = img.reshape(3,1,4,4)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch uses channels first, whereas TensorFlow user channels last\n",
    "# Convert channels last image to channels first\n",
    "img = np.random.rand(3,4,4,1)\n",
    "print(img)\n",
    "img = np.moveaxis(img, -1, 1) # OR img = img.transpose((2, 0, 1))\n",
    "print(img, img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown of batch of images\n",
    "img = torch.tensor(img)\n",
    "print(img[0]) #0th image\n",
    "print(img[0][0]) #1st colour channel of oth image\n",
    "print(img[0][0][0])#1st row of 0th image\n",
    "print(img[0][0][0][0])#1st element of 0th image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "# Say we want flattened images\n",
    "print(img.flatten()) #everything flattened\n",
    "print(img.flatten(start_dim=1)) #each image flattened\n",
    "# OR\n",
    "print(img.reshape(img.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5., 1.],\n",
      "        [2., 3., 5.],\n",
      "        [3., 4., 5.]])\n",
      "tensor(32.)\n",
      "9\n",
      "tensor(36000.)\n",
      "tensor(3.5556)\n",
      "tensor(1.4240)\n"
     ]
    }
   ],
   "source": [
    "# Reduction Ops\n",
    "x = torch.randint(1,9,(3,3))\n",
    "print(x)\n",
    "print(x.sum()) #sum of all elements\n",
    "print(x.numel()) #number of elements\n",
    "print(x.prod()) #product of all elements\n",
    "print(x.mean()) #mean\n",
    "print(x.std()) #standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 6])\n",
      "tensor([3, 6, 9])\n"
     ]
    }
   ],
   "source": [
    "# Sum\n",
    "x = torch.tensor([\n",
    "    [1,1,1],\n",
    "    [2,2,2],\n",
    "    [3,3,3]\n",
    "])\n",
    "print(x.sum(dim=0)) #rows(axis 0) will be added not addition along a row\n",
    "print(x.sum(dim=1)) #columns will be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 8., 2.],\n",
      "        [1., 1., 8.],\n",
      "        [6., 2., 4.]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# Argmax (Outputs index location of the maximum value in a tensor)\n",
    "x = torch.randint(1,9,(3,3))\n",
    "print(x)\n",
    "print(x.argmax()) #according to flattened tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3])\n",
      "3\n",
      "tensor([1, 2, 3])\n",
      "[1, 2, 3]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Conversion\n",
    "x = torch.tensor([3])\n",
    "print(x)\n",
    "print(x.item()) #Only scalar tensor\n",
    "\n",
    "x = torch.tensor([1,2,3])\n",
    "print(x)\n",
    "print(x.tolist()) #Python list\n",
    "print(type(x.numpy())) #numpy array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
